{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dos módulos necessários e declaração de constantes\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# quantidade de canais que as imagens de entrada possuem\n",
    "# escalar cor de cinza, entao 1\n",
    "CHANNEL = 1\n",
    "# valor da largura e da altura das imagens de entrada\n",
    "WIDTH_HEIGHT = 20\n",
    "# tamanho do batch\n",
    "BATCH = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load do arquivo de dados\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = np.loadtxt('exdata.csv', delimiter=',')\n",
    "\n",
    "# cada coluna tem um padrao de digito\n",
    "data = load[:-1].T\n",
    "\n",
    "# a ultima linha eh a classificacao do digito\n",
    "result = load[-1] \n",
    "# digito 0 corresponde ao valor 10\n",
    "result[result == 10] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pré-processamento dos dados e das classes\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trasformar cada linha (digito) em uma matriz 20 x 20 x 1\n",
    "data = data.reshape(data.shape[0], WIDTH_HEIGHT, WIDTH_HEIGHT, CHANNEL)\n",
    "\n",
    "# converte array de 1 dimensao para uma matriz de dimensao 10\n",
    "# ou seja, criar 10 classes, uma para cada digito possivel\n",
    "result = keras.utils.to_categorical(result, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separação dos dados em treinamento e teste\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_train, in_test, out_train, out_test = train_test_split(data, \n",
    "                                                          result,\n",
    "                                                          test_size=(25/100),\n",
    "                                                          train_size=(75/100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição da arquitetura da rede neural\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'pilha' de camadas lineares\n",
    "model = Sequential()\n",
    "\n",
    "# primeira camada precisa saber o que espera de entrada\n",
    "# Conv2D cria uma camada de 'convolution' (add cada elemento da imagem com o seu vizinho local)\n",
    "# isso eh feito atraves do input_shape\n",
    "# 32 eh o numero de filtros\n",
    "# relu = rectified linear unit\n",
    "model.add(Conv2D(32, \n",
    "                 kernel_size=(3, 3), \n",
    "                 activation='relu', \n",
    "                 input_shape=(WIDTH_HEIGHT, WIDTH_HEIGHT, CHANNEL)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# MaxPooling2D cria uma camada que faz um processo de discretizacao baseada em amostra\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Dropout cria uma camada de regularizacao\n",
    "# 0.25 eh a fracao da quantidade de entrada que entrara na camada\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten cria uma camada que 'flatteniza'\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense cria uma camada que representa uma multiplicacao de matrizes\n",
    "# 128 eh a dimensionalidade da saida\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compilação da rede neural\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuracao de que como sera o aprendizado de processo\n",
    "# para qualquer problema de classificacao deve-se usar o accuracy\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input dos dados de treinamento\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/10\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 1.4255 - acc: 0.5309 - val_loss: 0.8645 - val_acc: 0.7064\n",
      "Epoch 2/10\n",
      "3750/3750 [==============================] - 4s 952us/step - loss: 0.5193 - acc: 0.8403 - val_loss: 0.3326 - val_acc: 0.8864\n",
      "Epoch 3/10\n",
      "3750/3750 [==============================] - 4s 951us/step - loss: 0.3074 - acc: 0.9096 - val_loss: 0.1938 - val_acc: 0.9480\n",
      "Epoch 4/10\n",
      "3750/3750 [==============================] - 4s 952us/step - loss: 0.2354 - acc: 0.9315 - val_loss: 0.2181 - val_acc: 0.9312\n",
      "Epoch 5/10\n",
      "3750/3750 [==============================] - 4s 951us/step - loss: 0.1926 - acc: 0.9416 - val_loss: 0.1394 - val_acc: 0.9576\n",
      "Epoch 6/10\n",
      "3750/3750 [==============================] - 4s 950us/step - loss: 0.1524 - acc: 0.9555 - val_loss: 0.1227 - val_acc: 0.9632\n",
      "Epoch 7/10\n",
      "3750/3750 [==============================] - 4s 948us/step - loss: 0.1320 - acc: 0.9611 - val_loss: 0.1360 - val_acc: 0.9592\n",
      "Epoch 8/10\n",
      "3750/3750 [==============================] - 4s 956us/step - loss: 0.1202 - acc: 0.9651 - val_loss: 0.1055 - val_acc: 0.9680\n",
      "Epoch 9/10\n",
      "3750/3750 [==============================] - 4s 960us/step - loss: 0.1009 - acc: 0.9709 - val_loss: 0.1114 - val_acc: 0.9672\n",
      "Epoch 10/10\n",
      "3750/3750 [==============================] - 4s 956us/step - loss: 0.0826 - acc: 0.9752 - val_loss: 0.1098 - val_acc: 0.9712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f473ba70be0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size eh o numero de amostras por update do gradiente\n",
    "# epochs = um epoch eh uma iteracao sobre os dados fornecidos\n",
    "model.fit(in_train, out_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(in_test, out_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliação com os dados de teste\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste loss: 0.10976421747710556\n",
      "Teste acurácia: 0.9712\n"
     ]
    }
   ],
   "source": [
    "# valores do modelo no modo de teste \n",
    "score = model.evaluate(in_test, out_test, verbose=0)\n",
    "print('Teste loss:', score[0])\n",
    "print('Teste acurácia:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de confusão\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[127   0   0   0   0   0   0   0   0   0]\n",
      " [  0 115   0   1   0   0   1   0   0   0]\n",
      " [  1   0 119   0   0   0   0   0   1   0]\n",
      " [  0   0   4 122   0   0   0   0   1   1]\n",
      " [  0   0   0   0 120   0   0   1   0   0]\n",
      " [  0   1   0   0   0 120   3   0   0   0]\n",
      " [  1   2   0   0   1   0 136   0   0   0]\n",
      " [  0   3   0   0   1   0   0 113   0   2]\n",
      " [  0   1   0   1   0   1   1   0 107   1]\n",
      " [  0   1   0   1   0   0   0   4   0 135]]\n"
     ]
    }
   ],
   "source": [
    "# gera a predicao para o conjunto de teste\n",
    "prediction = model.predict(in_test, batch_size=BATCH, verbose=0)\n",
    "\n",
    "# ajuste dado para ter info correta\n",
    "prediction_classes = np.argmax(prediction, axis=1)\n",
    "out_test_classes = np.argmax(out_test, axis=1)\n",
    "\n",
    "# gera a 'confusion matrix'\n",
    "matrix = metrics.confusion_matrix(out_test_classes , prediction_classes)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       127\n",
      "          1       0.93      0.98      0.96       117\n",
      "          2       0.97      0.98      0.98       121\n",
      "          3       0.98      0.95      0.96       128\n",
      "          4       0.98      0.99      0.99       121\n",
      "          5       0.99      0.97      0.98       124\n",
      "          6       0.96      0.97      0.97       140\n",
      "          7       0.96      0.95      0.95       119\n",
      "          8       0.98      0.96      0.97       112\n",
      "          9       0.97      0.96      0.96       141\n",
      "\n",
      "avg / total       0.97      0.97      0.97      1250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# gera um relatorio com as principais metricas da classificacao\n",
    "report = metrics.classification_report(out_test_classes, prediction_classes)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precisão final\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão no conjunto de teste: 97.12%\n"
     ]
    }
   ],
   "source": [
    "# calcula a precisao da classificacao\n",
    "value = metrics.accuracy_score(out_test_classes, prediction_classes)\n",
    "print(\"Precisão no conjunto de teste: {:.2%}\".format(value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
